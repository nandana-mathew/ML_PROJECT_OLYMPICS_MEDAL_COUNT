{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Olympic Medal Prediction - Data Download and Preparation\n",
    "\n",
    "## Setup Instructions\n",
    "\n",
    "### 1. Install Required Packages\n",
    "```bash\n",
    "pip install kaggle wbdata pandas numpy requests openpyxl pycountry\n",
    "```\n",
    "\n",
    "### 2. Configure Kaggle API\n",
    "1. Go to https://www.kaggle.com/account\n",
    "2. Click \"Create New API Token\" - downloads `kaggle.json`\n",
    "3. Place it at:\n",
    "   - **Linux/Mac**: `~/.kaggle/kaggle.json`\n",
    "   - **Windows**: `C:\\Users\\<username>\\.kaggle\\kaggle.json`\n",
    "4. Set permissions (Linux/Mac): `chmod 600 ~/.kaggle/kaggle.json`\n",
    "\n",
    "### 3. Run All Cells\n",
    "This notebook will:\n",
    "- Download Olympic medal data from Kaggle\n",
    "- Pull World Bank development indicators\n",
    "- Download UNDP HDI data\n",
    "- Create country ISO3 mappings\n",
    "- Merge everything into `data/processed/olympics_merged.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Directory structure created\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import zipfile\n",
    "import wbdata\n",
    "import pycountry\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Create directory structure\n",
    "Path('data/raw/olympic').mkdir(parents=True, exist_ok=True)\n",
    "Path('data/raw/worldbank').mkdir(parents=True, exist_ok=True)\n",
    "Path('data/raw/hdi').mkdir(parents=True, exist_ok=True)\n",
    "Path('data/processed').mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"‚úì Directory structure created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Download Olympic Medal Data from Kaggle\n",
    "\n",
    "We'll use the `olympic-games-medal-tally-by-country` dataset which provides clean country √ó games medal totals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading andreinovikov/olympic-games from Kaggle...\n",
      "Dataset URL: https://www.kaggle.com/datasets/andreinovikov/olympic-games\n",
      "‚úì Downloaded files: ['medals_processed.csv', 'olympic_games.csv']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def download_kaggle_olympics_new():\n",
    "    \"\"\"Download the alternative Olympic dataset from Kaggle.\"\"\"\n",
    "    try:\n",
    "        import kaggle\n",
    "\n",
    "        dataset = 'andreinovikov/olympic-games'  # new dataset\n",
    "        dest_path = 'data/raw/olympic'\n",
    "        os.makedirs(dest_path, exist_ok=True)\n",
    "\n",
    "        print(f\"Downloading {dataset} from Kaggle...\")\n",
    "        kaggle.api.dataset_download_files(\n",
    "            dataset,\n",
    "            path=dest_path,\n",
    "            unzip=True\n",
    "        )\n",
    "\n",
    "        # List downloaded files\n",
    "        files = os.listdir(dest_path)\n",
    "        print(f\"‚úì Downloaded files: {files}\")\n",
    "\n",
    "        return True\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error downloading from Kaggle: {e}\")\n",
    "        print(\"\\nTroubleshooting:\")\n",
    "        print(\"1. Check kaggle.json is in correct location (~/.kaggle/kaggle.json)\")\n",
    "        print(\"2. Make sure you've accepted dataset terms on Kaggle website\")\n",
    "        print(\"3. Try downloading manually if API fails\")\n",
    "        return False\n",
    "\n",
    "# Run the download\n",
    "download_kaggle_olympics_new()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available files: ['medals_processed.csv', 'olympic_games.csv']\n",
      "‚úì Processed Olympic data saved: (1781, 12)\n"
     ]
    }
   ],
   "source": [
    "def load_and_prepare_olympic_data_new():\n",
    "    \"\"\"Load Olympic data from the new Kaggle dataset.\"\"\"\n",
    "    olympic_files = os.listdir('data/raw/olympic')\n",
    "    print(f\"Available files: {olympic_files}\")\n",
    "\n",
    "    # Usually the main CSV is named something like 'olympic_games.csv'\n",
    "    medals_file = [f for f in olympic_files if f.endswith('.csv')][0]\n",
    "    df = pd.read_csv(f'data/raw/olympic/{medals_file}')\n",
    "\n",
    "    # Rename columns to match your old workflow\n",
    "    df.rename(columns={\n",
    "        'country': 'country_name',\n",
    "        'year': 'year',\n",
    "        'games_type': 'games_type',\n",
    "        'gold': 'gold',\n",
    "        'silver': 'silver',\n",
    "        'bronze': 'bronze'\n",
    "    }, inplace=True)\n",
    "\n",
    "    # Compute total medals\n",
    "    df['total_medals'] = df['gold'] + df['silver'] + df['bronze']\n",
    "\n",
    "    # Save processed CSV\n",
    "    df.to_csv('data/raw/olympic/medals_processed.csv', index=False)\n",
    "    print(f\"‚úì Processed Olympic data saved: {df.shape}\")\n",
    "\n",
    "    return df\n",
    "\n",
    "# Load the dataset\n",
    "olympic_df = load_and_prepare_olympic_data_new()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Create Country ISO3 Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è  Unmapped countries (2):\n",
      "['Independent Olympic Athletes', 'Mixed team']\n",
      "\n",
      "‚úì Country mapping created: 152 countries\n",
      "  Mapped: 150\n",
      "‚úÖ Removed 6 non-national entries (['Independent Olympic Athletes', 'Mixed team'])\n",
      "Remaining rows: 1775\n",
      "Unique countries now: 150\n"
     ]
    }
   ],
   "source": [
    "def create_country_mapping():\n",
    "    \"\"\"Create mapping from country names to ISO3 codes, including special Olympic cases\"\"\"\n",
    "    \n",
    "    # ‚úÖ Extended manual mappings to cover all Olympic variations and historical countries\n",
    "    manual_mappings = {\n",
    "        # Standard corrections\n",
    "        'United States': 'USA',\n",
    "        'United States of America': 'USA',\n",
    "        'Great Britain': 'GBR',\n",
    "        'Russia': 'RUS',\n",
    "        'Russian Federation': 'RUS',\n",
    "        'ROC': 'RUS',  # Russian Olympic Committee\n",
    "        'Soviet Union': 'RUS',\n",
    "        'China': 'CHN',\n",
    "        \"People's Republic of China\": 'CHN',\n",
    "        'South Korea': 'KOR',\n",
    "        'Korea': 'KOR',\n",
    "        'Chinese Taipei': 'TWN',\n",
    "        'Hong Kong': 'HKG',\n",
    "        'Hong Kong, China': 'HKG',\n",
    "        'Iran': 'IRN',\n",
    "        'Netherlands': 'NLD',\n",
    "        'Czech Republic': 'CZE',\n",
    "        'Czechia': 'CZE',\n",
    "        'North Korea': 'PRK',\n",
    "        'Vietnam': 'VNM',\n",
    "        'Venezuela': 'VEN',\n",
    "        'Syria': 'SYR',\n",
    "        'Tanzania': 'TZA',\n",
    "        'Bahamas': 'BHS',\n",
    "        'Philippines': 'PHL',\n",
    "        'Moldova': 'MDA',\n",
    "        'Ivory Coast': 'CIV',\n",
    "        \"C√¥te d'Ivoire\": 'CIV',\n",
    "        'Turkey': 'TUR',\n",
    "        'T√ºrkiye': 'TUR',\n",
    "\n",
    "        # üèõ Historical / special teams\n",
    "        'Independent Olympic Athletes': None,\n",
    "        'Serbia and Montenegro': 'SRB',\n",
    "        'Czechoslovakia': 'CZE',\n",
    "        'Unified Team': 'RUS',\n",
    "        'German Democratic Republic (Germany)': 'DEU',\n",
    "        'Netherlands Antilles': 'NLD',\n",
    "        'USSR': 'RUS',\n",
    "        'Virgin Islands, US': 'VIR',\n",
    "        'Yugoslavia': 'SRB',\n",
    "        'Mixed team': None,\n",
    "    }\n",
    "\n",
    "    def get_iso3(country_name):\n",
    "        \"\"\"Get ISO3 code for a country name\"\"\"\n",
    "        # Manual override first\n",
    "        if country_name in manual_mappings:\n",
    "            return manual_mappings[country_name]\n",
    "        \n",
    "        # Try pycountry fuzzy search\n",
    "        try:\n",
    "            result = pycountry.countries.search_fuzzy(country_name)\n",
    "            return result[0].alpha_3\n",
    "        except:\n",
    "            return None\n",
    "    \n",
    "\n",
    "    # Create mapping from Olympic data\n",
    "    if 'olympic_df' in globals() and olympic_df is not None and 'country_name' in olympic_df.columns:\n",
    "        unique_countries = olympic_df['country_name'].unique()\n",
    "        \n",
    "        mapping_data = []\n",
    "        for country in unique_countries:\n",
    "            iso3 = get_iso3(country)\n",
    "            mapping_data.append({\n",
    "                'country_name': country,\n",
    "                'iso3': iso3\n",
    "            })\n",
    "        \n",
    "        mapping_df = pd.DataFrame(mapping_data)\n",
    "        \n",
    "        # Report unmapped countries\n",
    "        unmapped = mapping_df[mapping_df['iso3'].isnull()]\n",
    "        if len(unmapped) > 0:\n",
    "            print(f\"‚ö†Ô∏è  Unmapped countries ({len(unmapped)}):\")\n",
    "            print(unmapped['country_name'].tolist())\n",
    "        else:\n",
    "            print(\"‚úÖ All countries successfully mapped!\")\n",
    "        \n",
    "        # Save mapping\n",
    "        os.makedirs('data/raw', exist_ok=True)\n",
    "        mapping_df.to_csv('data/raw/country_iso3_mapping.csv', index=False)\n",
    "        print(f\"\\n‚úì Country mapping created: {len(mapping_df)} countries\")\n",
    "        print(f\"  Mapped: {len(mapping_df[mapping_df['iso3'].notnull()])}\")\n",
    "        \n",
    "        return mapping_df\n",
    "    \n",
    "    else:\n",
    "        print(\"‚ùå olympic_df not found or missing 'country_name' column.\")\n",
    "        return None\n",
    "\n",
    "# Run mapping\n",
    "country_mapping = create_country_mapping()\n",
    "# Clean up special non-national Olympic entries\n",
    "invalid_countries = ['Independent Olympic Athletes', 'Mixed team']\n",
    "\n",
    "before = len(olympic_df)\n",
    "olympic_df = olympic_df[~olympic_df['country_name'].isin(invalid_countries)]\n",
    "after = len(olympic_df)\n",
    "\n",
    "print(f\"‚úÖ Removed {before - after} non-national entries ({invalid_countries})\")\n",
    "print(f\"Remaining rows: {after}\")\n",
    "print(f\"Unique countries now: {olympic_df['country_name'].nunique()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Download World Bank Indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading World Bank data from 1960 to 2024...\n",
      "  Downloading population (SP.POP.TOTL)... ‚úì (17290 rows)\n",
      "  Downloading gdp_current_usd (NY.GDP.MKTP.CD)... ‚úì (17290 rows)\n",
      "  Downloading gdp_per_capita (NY.GDP.PCAP.CD)... ‚úì (17290 rows)\n",
      "  Downloading life_expectancy (SP.DYN.LE00.IN)... ‚úì (17290 rows)\n",
      "  Downloading adult_literacy_rate (SE.ADT.LITR.ZS)... ‚úì (17290 rows)\n",
      "  Downloading unemployment_rate (SL.UEM.TOTL.ZS)... ‚úì (17290 rows)\n",
      "\n",
      "‚ö†Ô∏è  Countries still not mapped to ISO3 (60):\n",
      "['Africa Eastern and Southern', 'Africa Western and Central', 'Arab World', 'Bahamas, The', 'Caribbean small states', 'Central Europe and the Baltics', 'Channel Islands', 'Early-demographic dividend', 'East Asia & Pacific', 'East Asia & Pacific (IDA & IBRD countries)', 'East Asia & Pacific (excluding high income)', 'Euro area', 'Europe & Central Asia', 'Europe & Central Asia (IDA & IBRD countries)', 'Europe & Central Asia (excluding high income)', 'European Union', 'Fragile and conflict affected situations', 'Heavily indebted poor countries (HIPC)', 'High income', 'IBRD only', 'IDA & IBRD total', 'IDA blend', 'IDA only', 'IDA total', 'Late-demographic dividend', 'Latin America & Caribbean', 'Latin America & Caribbean (excluding high income)', 'Latin America & the Caribbean (IDA & IBRD countries)', 'Least developed countries: UN classification', 'Low & middle income', 'Low income', 'Lower middle income', 'Micronesia, Fed. Sts.', 'Middle East, North Africa, Afghanistan & Pakistan', 'Middle East, North Africa, Afghanistan & Pakistan (IDA & IBRD)', 'Middle East, North Africa, Afghanistan & Pakistan (excluding high income)', 'Middle income', 'North America', 'Not classified', 'OECD members', 'Other small states', 'Pacific island small states', 'Post-demographic dividend', 'Pre-demographic dividend', 'Puerto Rico (US)', 'Small states', 'Somalia, Fed. Rep.', 'South Asia', 'South Asia (IDA & IBRD)', 'St. Kitts and Nevis', 'St. Lucia', 'St. Martin (French part)', 'St. Vincent and the Grenadines', 'Sub-Saharan Africa', 'Sub-Saharan Africa (IDA & IBRD countries)', 'Sub-Saharan Africa (excluding high income)', 'Upper middle income', 'Virgin Islands (U.S.)', 'West Bank and Gaza', 'World']\n",
      "\n",
      "‚úì World Bank combined data saved: (17290, 9)\n",
      "  Countries with ISO3: 77.4%\n"
     ]
    }
   ],
   "source": [
    "import wbdata\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import pycountry\n",
    "import os\n",
    "\n",
    "def download_world_bank_data(start_year=1960, end_year=2024):\n",
    "    \"\"\"Download World Bank indicators using wbdata (compatible with older versions)\"\"\"\n",
    "\n",
    "    indicators = {\n",
    "        'SP.POP.TOTL': 'population',\n",
    "        'NY.GDP.MKTP.CD': 'gdp_current_usd',\n",
    "        'NY.GDP.PCAP.CD': 'gdp_per_capita',\n",
    "        'SP.DYN.LE00.IN': 'life_expectancy',\n",
    "        'SE.ADT.LITR.ZS': 'adult_literacy_rate',\n",
    "        'SL.UEM.TOTL.ZS': 'unemployment_rate'\n",
    "    }\n",
    "\n",
    "    print(f\"Downloading World Bank data from {start_year} to {end_year}...\")\n",
    "\n",
    "    os.makedirs('data/raw/worldbank', exist_ok=True)\n",
    "    all_data = []\n",
    "\n",
    "    for wb_code, var_name in indicators.items():\n",
    "        print(f\"  Downloading {var_name} ({wb_code})...\", end=' ')\n",
    "        try:\n",
    "            # Download without any extra arguments\n",
    "            data = wbdata.get_dataframe({wb_code: var_name})\n",
    "            data = data.reset_index()\n",
    "            \n",
    "            # Convert date column to year\n",
    "            data['year'] = pd.to_datetime(data['date']).dt.year\n",
    "            \n",
    "            # Filter by year range\n",
    "            data = data[(data['year'] >= start_year) & (data['year'] <= end_year)]\n",
    "            \n",
    "            data = data[['country', 'year', var_name]]\n",
    "            \n",
    "            # Save CSV\n",
    "            data.to_csv(f'data/raw/worldbank/{var_name}.csv', index=False)\n",
    "\n",
    "            all_data.append(data)\n",
    "            print(f\"‚úì ({len(data)} rows)\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error: {e}\")\n",
    "\n",
    "    # Merge all indicators\n",
    "    if all_data:\n",
    "        wb_combined = all_data[0]\n",
    "        for df in all_data[1:]:\n",
    "            wb_combined = wb_combined.merge(df, on=['country', 'year'], how='outer')\n",
    "\n",
    "        # Add ISO3 codes\n",
    "        def get_iso3_wb(country_name):\n",
    "            try:\n",
    "                result = pycountry.countries.search_fuzzy(country_name)\n",
    "                return result[0].alpha_3\n",
    "            except:\n",
    "                return None\n",
    "\n",
    "        # Manual corrections for common World Bank country name mismatches\n",
    "        manual_iso_map = {\n",
    "            \"Egypt, Arab Rep.\": \"EGY\",\n",
    "            \"Iran, Islamic Rep.\": \"IRN\",\n",
    "            \"Korea, Rep.\": \"KOR\",\n",
    "            \"Korea, Dem. People's Rep.\": \"PRK\",\n",
    "            \"Russian Federation\": \"RUS\",\n",
    "            \"Syrian Arab Republic\": \"SYR\",\n",
    "            \"Venezuela, RB\": \"VEN\",\n",
    "            \"Vietnam\": \"VNM\",\n",
    "            \"Yemen, Rep.\": \"YEM\",\n",
    "            \"Congo, Rep.\": \"COG\",\n",
    "            \"Congo, Dem. Rep.\": \"COD\",\n",
    "            \"Gambia, The\": \"GMB\",\n",
    "            \"Hong Kong SAR, China\": \"HKG\",\n",
    "            \"Lao PDR\": \"LAO\",\n",
    "            \"Macao SAR, China\": \"MAC\",\n",
    "            \"Slovak Republic\": \"SVK\",\n",
    "            \"United States\": \"USA\",\n",
    "            \"United Kingdom\": \"GBR\"\n",
    "        }\n",
    "\n",
    "        wb_combined['iso3'] = wb_combined['country'].map(manual_iso_map).fillna(\n",
    "            wb_combined['country'].apply(get_iso3_wb)\n",
    "        )\n",
    "\n",
    "        # Report countries still not mapped\n",
    "        unmapped = wb_combined[wb_combined['iso3'].isnull()]['country'].unique()\n",
    "        if len(unmapped) > 0:\n",
    "            print(f\"\\n‚ö†Ô∏è  Countries still not mapped to ISO3 ({len(unmapped)}):\")\n",
    "            print(list(unmapped))\n",
    "        else:\n",
    "            print(\"\\n‚úì All countries successfully mapped to ISO3\")\n",
    "\n",
    "        wb_combined.to_csv('data/raw/worldbank_combined.csv', index=False)\n",
    "        print(f\"\\n‚úì World Bank combined data saved: {wb_combined.shape}\")\n",
    "        print(f\"  Countries with ISO3: {wb_combined['iso3'].notnull().sum() / len(wb_combined) * 100:.1f}%\")\n",
    "\n",
    "        return wb_combined\n",
    "\n",
    "    return None\n",
    "\n",
    "# Run it\n",
    "wb_data = download_world_bank_data()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Download UNDP HDI Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading HDI data...\n",
      "‚úì HDI data downloaded: (206, 1008)\n",
      "Columns: ['iso3', 'country', 'hdicode', 'region', 'hdi_rank_2021', 'hdi_1990', 'hdi_1991', 'hdi_1992', 'hdi_1993', 'hdi_1994']...\n"
     ]
    }
   ],
   "source": [
    "def download_hdi_data():\n",
    "    \"\"\"Download UNDP Human Development Index data\"\"\"\n",
    "    \n",
    "    print(\"Downloading HDI data...\")\n",
    "    \n",
    "    # UNDP HDI data URL (latest available)\n",
    "    url = 'https://hdr.undp.org/sites/default/files/2021-22_HDR/HDR21-22_Composite_indices_complete_time_series.csv'\n",
    "    \n",
    "    try:\n",
    "        hdi_df = pd.read_csv(url)\n",
    "        \n",
    "        print(f\"‚úì HDI data downloaded: {hdi_df.shape}\")\n",
    "        print(f\"Columns: {hdi_df.columns.tolist()[:10]}...\")  # Show first 10 columns\n",
    "        \n",
    "        # Reshape from wide to long format\n",
    "        # Find year columns (typically 1990-2021)\n",
    "        year_cols = [col for col in hdi_df.columns if col.isdigit()]\n",
    "        \n",
    "        if year_cols:\n",
    "            id_cols = [col for col in hdi_df.columns if col not in year_cols]\n",
    "            hdi_long = hdi_df.melt(\n",
    "                id_vars=id_cols,\n",
    "                value_vars=year_cols,\n",
    "                var_name='year',\n",
    "                value_name='hdi'\n",
    "            )\n",
    "            hdi_long['year'] = hdi_long['year'].astype(int)\n",
    "            \n",
    "            # Keep relevant columns\n",
    "            keep_cols = ['country', 'iso3', 'year', 'hdi']\n",
    "            available_cols = [c for c in keep_cols if c in hdi_long.columns]\n",
    "            \n",
    "            if 'iso3' not in available_cols and 'country' in available_cols:\n",
    "                # Add ISO3 codes\n",
    "                def get_iso3_hdi(country_name):\n",
    "                    try:\n",
    "                        result = pycountry.countries.search_fuzzy(str(country_name))\n",
    "                        return result[0].alpha_3\n",
    "                    except:\n",
    "                        return None\n",
    "                hdi_long['iso3'] = hdi_long['country'].apply(get_iso3_hdi)\n",
    "                available_cols.append('iso3')\n",
    "            \n",
    "            hdi_clean = hdi_long[available_cols].copy()\n",
    "            \n",
    "            # Remove missing HDI values\n",
    "            hdi_clean = hdi_clean[hdi_clean['hdi'].notnull()]\n",
    "            \n",
    "            # Save\n",
    "            hdi_clean.to_csv('data/raw/hdi/hdi_data.csv', index=False)\n",
    "            print(f\"‚úì HDI data processed and saved: {hdi_clean.shape}\")\n",
    "            \n",
    "            return hdi_clean\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error downloading HDI data: {e}\")\n",
    "        print(\"Continuing without HDI data...\")\n",
    "        return None\n",
    "\n",
    "hdi_data = download_hdi_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Merge All Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_all_data_full(olympic_df, country_mapping, wb_data, hdi_data):\n",
    "    \"\"\"\n",
    "    Merge Olympic, World Bank, and HDI data, including all participating countries.\n",
    "    Creates 0-medal rows for countries that didn't win.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"MERGING ALL DATASETS (INCLUDE ZERO-MEDALS)\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    if olympic_df is None:\n",
    "        print(\"‚ùå No Olympic data available\")\n",
    "        return None\n",
    "    \n",
    "    # Add ISO3 codes first\n",
    "    if country_mapping is not None:\n",
    "        olympic_df = olympic_df.merge(\n",
    "            country_mapping[['country_name', 'iso3']],\n",
    "            on='country_name',\n",
    "            how='left'\n",
    "        )\n",
    "        print(f\"After adding ISO3: {olympic_df.shape}\")\n",
    "        print(f\"  Missing ISO3: {olympic_df['iso3'].isnull().sum()}\")\n",
    "    \n",
    "    # Get list of all countries and games\n",
    "    all_countries = country_mapping['iso3'].dropna().unique()\n",
    "    all_games = olympic_df[['year','games_type']].drop_duplicates()\n",
    "    \n",
    "    # Create full country √ó games table\n",
    "    full_rows = []\n",
    "    for year, game in all_games.values:\n",
    "        for iso3 in all_countries:\n",
    "            full_rows.append([iso3, year, game])\n",
    "    \n",
    "    full_df = pd.DataFrame(full_rows, columns=['iso3','year','games_type'])\n",
    "    \n",
    "    # Merge medal info (left join so missing medals become NaN)\n",
    "    full_df = full_df.merge(\n",
    "        olympic_df[['iso3','year','games_type','gold','silver','bronze','total_medals']],\n",
    "        on=['iso3','year','games_type'],\n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    # Fill missing medals with 0\n",
    "    for col in ['gold','silver','bronze','total_medals']:\n",
    "        full_df[col] = full_df[col].fillna(0)\n",
    "    \n",
    "    # Classification target\n",
    "    full_df['has_medal'] = (full_df['total_medals'] > 0).astype(int)\n",
    "    \n",
    "    print(f\"\\n‚úÖ Medal coverage after adding zero-medal countries:\")\n",
    "    print(full_df['has_medal'].value_counts())\n",
    "    \n",
    "    # Merge World Bank indicators\n",
    "    if wb_data is not None:\n",
    "        wb_subset = wb_data[wb_data['iso3'].notnull()].copy()\n",
    "        full_df = full_df.merge(\n",
    "            wb_subset,\n",
    "            on=['iso3','year'],\n",
    "            how='left',\n",
    "            suffixes=('', '_wb')\n",
    "        )\n",
    "        \n",
    "        wb_indicators = ['population', 'gdp_current_usd', 'gdp_per_capita', \n",
    "                         'life_expectancy', 'adult_literacy_rate', 'unemployment_rate']\n",
    "        for indicator in wb_indicators:\n",
    "            if indicator in full_df.columns:\n",
    "                full_df[indicator] = full_df.groupby('iso3')[indicator].fillna(method='ffill')\n",
    "    \n",
    "    # Merge HDI\n",
    "    if hdi_data is not None:\n",
    "        hdi_subset = hdi_data[hdi_data['iso3'].notnull()][['iso3','year','hdi']].copy()\n",
    "        full_df = full_df.merge(\n",
    "            hdi_subset,\n",
    "            on=['iso3','year'],\n",
    "            how='left'\n",
    "        )\n",
    "        full_df['hdi'] = full_df.groupby('iso3')['hdi'].fillna(method='ffill')\n",
    "    \n",
    "    # Reorder columns\n",
    "    base_cols = ['iso3','year','games_type']\n",
    "    medal_cols = ['gold','silver','bronze','total_medals','has_medal']\n",
    "    other_cols = [c for c in full_df.columns if c not in base_cols + medal_cols]\n",
    "    full_df = full_df[base_cols + medal_cols + other_cols]\n",
    "    \n",
    "    # Save final dataset\n",
    "    full_df.to_csv('data/processed/olympics_merged.csv', index=False)\n",
    "    \n",
    "    print(f\"\\nüéØ FINAL MERGED DATA: {full_df.shape}\")\n",
    "    print(f\"Columns: {full_df.columns.tolist()}\")\n",
    "    print(f\"Data coverage: years {full_df['year'].min()}-{full_df['year'].max()}, countries {full_df['iso3'].nunique()}\")\n",
    "    \n",
    "    return full_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "MERGING ALL DATASETS (INCLUDE ZERO-MEDALS)\n",
      "============================================================\n",
      "After adding ISO3: (1775, 13)\n",
      "  Missing ISO3: 0\n",
      "\n",
      "‚úÖ Medal coverage after adding zero-medal countries:\n",
      "has_medal\n",
      "0    5511\n",
      "1    1775\n",
      "Name: count, dtype: int64\n",
      "\n",
      "üéØ FINAL MERGED DATA: (7390, 15)\n",
      "Columns: ['iso3', 'year', 'games_type', 'gold', 'silver', 'bronze', 'total_medals', 'has_medal', 'country', 'population', 'gdp_current_usd', 'gdp_per_capita', 'life_expectancy', 'adult_literacy_rate', 'unemployment_rate']\n",
      "Data coverage: years 1896-2022, countries 137\n",
      "\n",
      "Sample of merged data (including zero-medals):\n",
      "  iso3  year games_type  gold  silver  bronze  total_medals  has_medal  \\\n",
      "0  AUS  2022     Winter   1.0     2.0     1.0           4.0          1   \n",
      "1  AUT  2022     Winter   7.0     7.0     4.0          18.0          1   \n",
      "2  BLR  2022     Winter   0.0     2.0     0.0           2.0          1   \n",
      "3  BEL  2022     Winter   1.0     0.0     1.0           2.0          1   \n",
      "4  CAN  2022     Winter   4.0     8.0    14.0          26.0          1   \n",
      "5  CZE  2022     Winter   1.0     0.0     1.0           2.0          1   \n",
      "6  EST  2022     Winter   0.0     0.0     1.0           1.0          1   \n",
      "7  FIN  2022     Winter   2.0     2.0     4.0           8.0          1   \n",
      "8  FRA  2022     Winter   5.0     7.0     2.0          14.0          1   \n",
      "9  DEU  2022     Winter  12.0    10.0     5.0          27.0          1   \n",
      "\n",
      "     country  population  gdp_current_usd  gdp_per_capita  life_expectancy  \\\n",
      "0  Australia  26014399.0     1.690858e+12    64997.013654        83.200000   \n",
      "1    Austria   9041851.0     4.717736e+11    52176.664914        81.295122   \n",
      "2    Belarus   9228071.0     7.377518e+10     7994.648061        74.103366   \n",
      "3    Belgium  11680210.0     5.936146e+11    50822.251854        81.748780   \n",
      "4     Canada  38935934.0     2.190411e+12    56256.800726        81.245366   \n",
      "5    Czechia  10672118.0     3.018312e+11    28282.223672        78.929268   \n",
      "6    Estonia   1348840.0     3.837605e+10    28451.147783        77.843902   \n",
      "7    Finland   5556106.0     2.802531e+11    50440.560225        81.187805   \n",
      "8     France  68065015.0     2.796302e+12    41082.811932        82.129268   \n",
      "9    Germany  83797985.0     4.163596e+12    49686.115458        80.608049   \n",
      "\n",
      "   adult_literacy_rate  unemployment_rate  \n",
      "0                  NaN              3.728  \n",
      "1                  NaN              4.992  \n",
      "2                  NaN              3.574  \n",
      "3                  NaN              5.570  \n",
      "4                  NaN              5.279  \n",
      "5                  NaN              2.224  \n",
      "6                  NaN              5.571  \n",
      "7                  NaN              6.719  \n",
      "8                  NaN              7.308  \n",
      "9                  NaN              3.120  \n",
      "\n",
      "Class balance in 'has_medal':\n",
      "has_medal\n",
      "0    5551\n",
      "1    1839\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "final_data = merge_all_data_full(olympic_df, country_mapping, wb_data, hdi_data)\n",
    "\n",
    "# Quick check\n",
    "print(\"\\nSample of merged data (including zero-medals):\")\n",
    "print(final_data.head(10))\n",
    "\n",
    "# Check class balance\n",
    "print(\"\\nClass balance in 'has_medal':\")\n",
    "print(final_data['has_medal'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### Files Created:\n",
    "- `data/raw/olympic/` - Raw Olympic medal data\n",
    "- `data/raw/worldbank/` - Individual World Bank indicator files\n",
    "- `data/raw/worldbank_combined.csv` - Combined World Bank data\n",
    "- `data/raw/hdi/hdi_data.csv` - UNDP HDI data\n",
    "- `data/raw/country_iso3_mapping.csv` - Country name to ISO3 mapping\n",
    "- `data/processed/olympics_merged.csv` - **Final merged dataset**\n",
    "\n",
    "### Next Steps:\n",
    "1. Run `train_two_stage_model.ipynb` to train the prediction model\n",
    "2. Use `evaluate_and_report.ipynb` to evaluate and generate reports\n",
    "3. Launch `streamlit run app.py` for interactive predictions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
